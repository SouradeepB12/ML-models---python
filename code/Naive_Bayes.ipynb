{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb1bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f9f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    '''\n",
    "    Bayes Theorem form\n",
    "    P(y|X) = P(X|y) * P(y) / P(X)\n",
    "    '''\n",
    "    def calc_prior(self, features, target):\n",
    "        '''\n",
    "        prior probability P(y)\n",
    "        calculate prior probabilities\n",
    "        '''\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "\n",
    "        return self.prior\n",
    "    \n",
    "    def calc_statistics(self, features, target):\n",
    "        '''\n",
    "        calculate mean, variance for each column and convert to numpy array\n",
    "        ''' \n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "              \n",
    "        return self.mean, self.var\n",
    "    \n",
    "    def gaussian_density(self, class_idx, x):     \n",
    "        '''\n",
    "        calculate probability from gaussian density function (normally distributed)\n",
    "        we will assume that probability of specific target value given specific class is normally distributed \n",
    "        \n",
    "        probability density function derived from wikipedia:\n",
    "        (1/√2pi*σ) * exp((-1/2)*((x-μ)^2)/(2*σ²)), where μ is mean, σ² is variance, σ is quare root of variance (standard deviation)\n",
    "        '''\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "#         numerator = np.exp(-((x-mean)**2 / (2 * var)))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for i in range(self.count):\n",
    "            prior = np.log(self.prior[i]) ## use the log to make it more numerically stable\n",
    "            conditional = np.sum(np.log(self.gaussian_density(i, x))) # use the log to make it more numerically stable\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        # return class with highest posterior probability\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "     \n",
    "\n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        self.calc_statistics(features, target)\n",
    "        self.calc_prior(features, target)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        preds = [self.calc_posterior(f) for f in features.to_numpy()]\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "82678d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape =  (714, 4)\n",
      "labels.shape =  (714,)\n"
     ]
    }
   ],
   "source": [
    "##Importing dataset\n",
    "urlfile = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "data = pd.read_csv(urlfile)\n",
    "#print(data.shape)\n",
    "#print(data)\n",
    "\n",
    "##Remove unwanted features\n",
    "data.drop(['PassengerId','Name','SibSp','Parch','Ticket', 'Fare','Cabin','Embarked'],axis='columns',inplace=True)\n",
    "##Drop NaN values from the train set\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "##Convert categorical variable to numeric\n",
    "features = ['Pclass','Age', 'Sex']\n",
    "target = 'Survived'\n",
    "\n",
    "data = data[features + [target]]\n",
    "data['Sex'] = data['Sex'].replace([\"female\", \"male\"], [0, 1])\n",
    "data['Age'] = pd.qcut(data['Age'], 10, labels=False)\n",
    "print('data.shape = ', data.shape)\n",
    "#print(data)\n",
    "\n",
    "\n",
    "labels = data[target].values\n",
    "#print(labels)\n",
    "print('labels.shape = ', labels.shape)\n",
    "\n",
    "##Split dataset into training set (80%) and validatation set (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=1)\n",
    "#X_train.head()\n",
    "#y_train.head()\n",
    "\n",
    "##Split training set (80%) in two parts - for training (70%) and testing (30%)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, test_size=0.3, random_state=12)\n",
    "#print(X_train1)\n",
    "#print(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a217e8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics\n",
      "Accuracy of Naive Bayes =  0.6337209302325582\n",
      "Validity of Naive Bayes =  0.6013986013986014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\AppData\\Local\\Temp/ipykernel_27944/3682310222.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp/ipykernel_27944/3682310222.py:34: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp/ipykernel_27944/3682310222.py:37: RuntimeWarning: invalid value encountered in true_divide\n",
      "  prob = numerator / denominator\n"
     ]
    }
   ],
   "source": [
    "##Train and test the model\n",
    "x = NaiveBayesClassifier()\n",
    "x.fit(X_train1, y_train1)\n",
    "predictions_test = x.predict(X_test1)\n",
    "accuracy_test = x.accuracy(y_test1, predictions_test)\n",
    "\n",
    "##Validate the model\n",
    "predictions_val = x.predict(X_val)\n",
    "accuracy_val = x.accuracy(y_val, predictions_val)\n",
    "\n",
    "print('Model metrics')\n",
    "print('Accuracy of Naive Bayes = ', accuracy_test)\n",
    "print('Validity of Naive Bayes = ', accuracy_val)\n",
    "\n",
    "##Determining probability of survival for each class\n",
    "#print('Probability of each class')\n",
    "#print('Survive = 0: %.2f' % classifier.class_prior_[0])\n",
    "#print('Survive = 1: %.2f' % classifier.class_prior_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cea5b3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics with sklearn Naive Bayes Classifier\n",
      "Accuracy of Naive Bayes =  1.0\n",
      "Validity of Naive Bayes =  1.0\n"
     ]
    }
   ],
   "source": [
    "##Comparison with sklearn Naive Bayes Classifier\n",
    "\n",
    "##Initialize the classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "##Fitting the first part of data\n",
    "classifier.fit(X_train1, y_train1)\n",
    "\n",
    "predictions_test = classifier.predict(X_test1)\n",
    "accuracy_test = accuracy_score(y_test1, predictions_test)\n",
    "\n",
    "predictions_val = classifier.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, predictions_val)\n",
    "\n",
    "print('Model metrics with sklearn Naive Bayes Classifier')\n",
    "print('Accuracy of Naive Bayes = ', accuracy_test)\n",
    "print('Validity of Naive Bayes = ', accuracy_val)\n",
    "\n",
    "##Determining probability of survival for each class\n",
    "#print('Probability of each class')\n",
    "#print('Survive = 0: %.2f' % classifier.class_prior_[0])\n",
    "#print('Survive = 1: %.2f' % classifier.class_prior_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df5984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
